{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-BmDD5RbyTZn",
      "metadata": {
        "id": "-BmDD5RbyTZn"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7tUrskDXyJrq",
      "metadata": {
        "id": "7tUrskDXyJrq"
      },
      "source": [
        "# Companion Code for SOL310: Adding Agentic Aware Security Next '25\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/hugoselbie/Companion_SOL310_Next25_Agentic-Aware-Security/blob/main/notebook.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2Fhugoselbie%2FCompanion_SOL310_Next25_Agentic-Aware-Security%2Fmain%2Fnotebook.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/hugoselbie/Companion_SOL310_Next25_Agentic-Aware-Security/main/notebook.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/hugoselbie/Companion_SOL310_Next25_Agentic-Aware-Security\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "<div style=\"clear: both;\"></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "704f4b1e-bfa2-4597-b768-8bec2e77e3fa",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "704f4b1e-bfa2-4597-b768-8bec2e77e3fa"
      },
      "source": [
        "# Setting up the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "REAjv_pA9vH3",
      "metadata": {
        "id": "REAjv_pA9vH3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet \\\n",
        "    \"google-cloud-aiplatform[agent_engines,langchain]\" \\\n",
        "    langgraph \\\n",
        "    langchain \\\n",
        "    google-cloud-aiplatform google-cloud-discoveryengine \\\n",
        "    cloudpickle==3.0.0 \\\n",
        "    \"pydantic>=2.10\" \\\n",
        "    requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "25521614-ad0d-4692-a3a5-eafdf37566fd",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "25521614-ad0d-4692-a3a5-eafdf37566fd"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "import json\n",
        "import os\n",
        "\n",
        "import subprocess\n",
        "import time\n",
        "import operator\n",
        "from copy import deepcopy\n",
        "from typing import TypedDict, Annotated, List, Literal, Optional\n",
        "from dataclasses import dataclass\n",
        "import google.auth\n",
        "import google.auth.transport.requests\n",
        "import requests\n",
        "import vertexai\n",
        "from langgraph.graph import START, StateGraph\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.prebuilt import ToolNode, tools_condition, InjectedState\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "from vertexai import agent_engines\n",
        "from vertexai.preview.reasoning_engines import LangchainAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "iyWsFPbmOLI6",
      "metadata": {
        "id": "iyWsFPbmOLI6"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m auth\n\u001b[32m      2\u001b[39m auth.authenticate_user()\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7480b97",
      "metadata": {},
      "source": [
        "# Project Setup\n",
        "To execute the usecases outlined in SOL310: Adding Agentic Aware Security presented at Next '25, there are a few setup parameters to go through. The case study is using vertex ai search with an associated document datastore derived from documents that are stored in GCS. \n",
        "\n",
        "To execute the example below we're expecting you to have already configured a VAIS search app with associated datastore and have documents that are stored in a known GCS bucket that you have read/write permissions on. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Tx0Gjxgg-LnW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Tx0Gjxgg-LnW",
        "outputId": "271c4cc0-a9ba-407c-b90c-e4939e55e90c"
      },
      "outputs": [],
      "source": [
        "PROJECT_NUMBER = 1077649599081\n",
        "PROJECT_ID = 'big-data-379417' #@param {type:\"string\"}\n",
        "BUCKET_NAME = 'data_storage_aiml_hugo' #@param {type:\"string\"}\n",
        "DATA_STORE_ID = 'test-subfolder_1697051023694'  #@param {type:\"string\"} \n",
        "SEARCH_APP = 'test-deloitte_1697050551691'  #@param {type:\"string\"} \n",
        "LOCATION = 'global' #@param {type:\"string\"} \n",
        "API_DOMAIN = 'discoveryengine' #@param {type:\"string\"}\n",
        "\n",
        "SEARCH_URL = f'https://{API_DOMAIN}.googleapis.com/v1alpha/projects/{PROJECT_NUMBER}/locations/{LOCATION}/collections/default_collection/engines/{SEARCH_APP}/servingConfigs/default_search:search'\n",
        "LIST_DOCUMENTS_URL = f'https://{API_DOMAIN}.googleapis.com/v1/projects/{PROJECT_NUMBER}/locations/{LOCATION}/collections/default_collection/dataStores/{DATA_STORE_ID}/branches/default_branch/documents'\n",
        "CREATE_DOCUMENT_URL_TEMPLATE = f'https://{API_DOMAIN}.googleapis.com/v1/projects/{PROJECT_NUMBER}/locations/{LOCATION}/collections/default_collection/dataStores/{DATA_STORE_ID}/branches/default_branch/documents?documentId={{}}'\n",
        "DOCUMENT_URL_TEMPLATE = f'https://{API_DOMAIN}.googleapis.com/v1/projects/{PROJECT_NUMBER}/locations/{LOCATION}/collections/default_collection/dataStores/{DATA_STORE_ID}/branches/default_branch/documents/{{}}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bf4da554-a3ce-44d8-bfba-cfdc805b368d",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "bf4da554-a3ce-44d8-bfba-cfdc805b368d"
      },
      "outputs": [],
      "source": [
        "os.environ['LOCAL'] = 'true'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "442f968e-2d02-4753-87ec-854c80fb8666",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "442f968e-2d02-4753-87ec-854c80fb8666"
      },
      "source": [
        "# Defining access control and getting permission information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9eee5068-8425-4a1c-8296-a1209a5932d5",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "9eee5068-8425-4a1c-8296-a1209a5932d5"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Access:\n",
        "    scope: str\n",
        "    specifier: str\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return (self.scope, self.specifier) < (other.scope, other.specifier)\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self.scope, self.specifier))\n",
        "\n",
        "    def match(self, other):\n",
        "        if self.scope != other.scope:\n",
        "            return None\n",
        "        if self.specifier == '*':\n",
        "            return other\n",
        "        if other.specifier == '*':\n",
        "            return self\n",
        "        if self.specifier == other.specifier:\n",
        "            return self\n",
        "        return None\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        return f'{self.scope}_{self.specifier}'\n",
        "\n",
        "\n",
        "class Restriction:\n",
        "\n",
        "    HASH_OUTPUT_BYTES = 16\n",
        "\n",
        "    def __init__(self, access):\n",
        "        self.accesses = [access]\n",
        "\n",
        "    def update(self, access):\n",
        "        if access in self.accesses:\n",
        "            raise ValueError('this access is already present')\n",
        "        if access.scope in (x.scope for x in self.accesses):\n",
        "            raise ValueError('access with the same scope is already present')\n",
        "        self.accesses.append(access)\n",
        "        self.accesses.sort()  # we want to have a stable order\n",
        "\n",
        "    def __str__(self):\n",
        "        return ' & '.join(str(x) for x in self.accesses)\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(tuple(self.accesses))  # already sorted\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self.accesses == other.accesses\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self)\n",
        "\n",
        "    @property\n",
        "    def hash(self):\n",
        "        string = str(self)\n",
        "        return hashlib.shake_128(string.encode()).hexdigest(self.HASH_OUTPUT_BYTES)\n",
        "\n",
        "    def match(self, other):\n",
        "        if len(self.accesses) != len(other.accesses):\n",
        "            return None\n",
        "\n",
        "        accesses = []\n",
        "        for access in self.accesses:\n",
        "            matched = [access.match(x) for x in other.accesses]\n",
        "            matched = [x for x in matched if x]\n",
        "            if not matched:\n",
        "                break\n",
        "            assert len(matched) == 1\n",
        "            accesses.extend(matched)\n",
        "\n",
        "        if not accesses:\n",
        "            return None\n",
        "        restriction = Restriction(accesses.pop())\n",
        "        while accesses:\n",
        "            restriction.update(accesses.pop())\n",
        "        return restriction\n",
        "\n",
        "    def has_wildcard(self):\n",
        "        return any(x for x in self.accesses if x.specifier == '*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "019f2f82-b0c2-461f-8898-639a1008fb13",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "019f2f82-b0c2-461f-8898-639a1008fb13"
      },
      "outputs": [],
      "source": [
        "class Principal:\n",
        "\n",
        "    def __new__(cls, id_):\n",
        "        instance = cls.instances.get(id_)\n",
        "        if instance is None:\n",
        "            instance = super().__new__(cls)\n",
        "            cls.instances[id_] = instance\n",
        "        return instance\n",
        "\n",
        "    def __init__(self, id_, *args, **kwargs):\n",
        "        if hasattr(self, 'id'):  # is initialized?\n",
        "            return\n",
        "        self.id = id_\n",
        "        self.read_restriction = None\n",
        "        self.write_restriction = None\n",
        "        self.membership = set()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__.__name__}({self.id!r})'\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.id)\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self.id < other.id\n",
        "\n",
        "    @property\n",
        "    def membership_expanded(self):\n",
        "        expanded = set()\n",
        "        stack = list(self.membership)\n",
        "        while stack:\n",
        "            group = stack.pop()\n",
        "            expanded.add(group)\n",
        "            stack.extend(group.membership)\n",
        "        return expanded\n",
        "\n",
        "    def restrict_read(self, access):\n",
        "        if self.read_restriction is None:\n",
        "            self.read_restriction = Restriction(access)\n",
        "        else:\n",
        "            self.read_restriction.update(access)\n",
        "\n",
        "    def restrict_write(self, access):\n",
        "        if self.write_restriction is None:\n",
        "            self.write_restriction = Restriction(access)\n",
        "        else:\n",
        "            self.write_restriction.update(access)\n",
        "\n",
        "    @classmethod\n",
        "    def all(cls):\n",
        "        return cls.instances\n",
        "\n",
        "    @classmethod\n",
        "    def clear_all(cls):\n",
        "        cls.instances.clear()\n",
        "\n",
        "    @property\n",
        "    def read_restrictions(self):\n",
        "        restrictions = {group.read_restriction for group in self.membership_expanded}\n",
        "        restrictions.add(self.read_restriction)\n",
        "        return {x for x in restrictions if x}\n",
        "\n",
        "    @property\n",
        "    def write_restrictions(self):\n",
        "        restrictions = {group.write_restriction for group in self.membership_expanded}\n",
        "        restrictions.add(self.write_restriction)\n",
        "        return {x for x in restrictions if x}\n",
        "\n",
        "\n",
        "class Individual(Principal):\n",
        "    pass\n",
        "\n",
        "\n",
        "class User(Individual):\n",
        "\n",
        "    instances = {}\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        if hasattr(self, 'initialized'):\n",
        "            return\n",
        "        access = Access(scope='user', specifier=self.id)\n",
        "        self.restrict_read(access)\n",
        "        self.restrict_write(access)\n",
        "        self.initialized = ...\n",
        "\n",
        "\n",
        "class Agent(Individual):\n",
        "\n",
        "    instances = {}\n",
        "\n",
        "\n",
        "class Group(Principal):\n",
        "\n",
        "    instances = {}\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        if hasattr(self, 'initialized'):\n",
        "            return\n",
        "        self.members = set()\n",
        "        self.initialized = ...\n",
        "\n",
        "    @property\n",
        "    def members_expanded(self):\n",
        "        expanded = set()\n",
        "        stack = list(self.members)\n",
        "        while stack:\n",
        "            member = stack.pop()\n",
        "            expanded.add(member)\n",
        "            if isinstance(member, Group):\n",
        "                stack.extend(member.members)\n",
        "        return expanded\n",
        "\n",
        "    def add_member(self, member):\n",
        "        if member in self.members:\n",
        "            raise ValueError('already a member')\n",
        "        if isinstance(member, Group):\n",
        "            if self.id == member.id:\n",
        "                raise ValueError('cannot be own member')\n",
        "            if self in member.members_expanded:\n",
        "                raise ValueError('cycle detected')\n",
        "        self.members.add(member)\n",
        "        member.membership.add(self)\n",
        "\n",
        "    def remove_member(self, member):\n",
        "        if member not in self.members:\n",
        "            raise ValueError('not a member')\n",
        "        self.members.remove(member)\n",
        "        member.membership.remove(self)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eH2GHKrDl0t",
      "metadata": {
        "id": "1eH2GHKrDl0t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e5ac3f31-58b8-4947-88a0-5ce5e50d570b",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "e5ac3f31-58b8-4947-88a0-5ce5e50d570b"
      },
      "outputs": [],
      "source": [
        "def reconcile_restrictions(*restriction_collections):\n",
        "    if len(restriction_collections) < 2:\n",
        "        raise ValueError('at least 2 collections has to be provided')\n",
        "    stack = list(restriction_collections)\n",
        "    first = stack.pop()\n",
        "    while stack:\n",
        "        second = stack.pop()\n",
        "        merged = set()\n",
        "        for first_restriction in first:\n",
        "            for second_restriction in second:\n",
        "                match = first_restriction.match(second_restriction)\n",
        "                if match is not None:\n",
        "                    merged.add(match)\n",
        "        first = merged\n",
        "    # wildcard cannot be present in the output collection\n",
        "    without_wildcard = {x for x in merged if not x.has_wildcard()}\n",
        "    return without_wildcard\n",
        "\n",
        "def get_filter(restrictions):\n",
        "    if not restrictions:\n",
        "        return None\n",
        "    hashes = [x.hash for x in restrictions]\n",
        "    filter_template = 'restrictions:ANY({})'\n",
        "    li = ','.join(f'\"{x}\"' for x in hashes)\n",
        "    the_filter = filter_template.format(li)\n",
        "    return the_filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cf29d543-4ea5-4ca1-8945-e94875394bbb",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "cf29d543-4ea5-4ca1-8945-e94875394bbb"
      },
      "outputs": [],
      "source": [
        "def upload_choices(principal):\n",
        "    return {\n",
        "        ' '.join(x.name for x in restriction.accesses): restriction\n",
        "        for restriction in principal.write_restrictions\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bea0f19a-f2b4-4967-b3a3-f54ef7000234",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "bea0f19a-f2b4-4967-b3a3-f54ef7000234"
      },
      "source": [
        "# Interacting with Vertex AI data store's documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2538a4f4-1710-4728-9279-64775f94ff7f",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "2538a4f4-1710-4728-9279-64775f94ff7f"
      },
      "outputs": [],
      "source": [
        "def get_token():\n",
        "    if os.environ.get('LOCAL'):\n",
        "        output = subprocess.run(['gcloud', 'auth', 'print-access-token'], capture_output=True, text=True)\n",
        "        token = output.stdout.strip()\n",
        "        return token\n",
        "    creds, _ = google.auth.default()\n",
        "    auth_req = google.auth.transport.requests.Request()\n",
        "    creds.refresh(auth_req)\n",
        "    token = creds.token\n",
        "    return token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "c67c3b77-c946-44d2-a285-2827f1617c21",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "c67c3b77-c946-44d2-a285-2827f1617c21"
      },
      "outputs": [],
      "source": [
        "class Resource:\n",
        "    pass\n",
        "\n",
        "class Row(Resource):\n",
        "    pass\n",
        "\n",
        "@dataclass\n",
        "class Document(Resource):\n",
        "    id: str\n",
        "    restrictions: List[Restriction]\n",
        "    metadata: dict\n",
        "    mime: str\n",
        "    uri: str\n",
        "\n",
        "    @property\n",
        "    def title(self):\n",
        "        return self.uri.rsplit('/', maxsplit=1)[-1].split('.')[0]\n",
        "\n",
        "    @staticmethod\n",
        "    def _headers():\n",
        "        token = get_token()\n",
        "        headers = {\n",
        "            'Content-Type': 'application/json',\n",
        "            'Authorization': f'Bearer {token}'\n",
        "        }\n",
        "        return headers\n",
        "\n",
        "    @classmethod\n",
        "    def list_all(cls):\n",
        "        response = requests.get(LIST_DOCUMENTS_URL, headers=cls._headers())\n",
        "        return response.json()\n",
        "\n",
        "    def as_resource(self):\n",
        "        metadata = deepcopy(self.metadata)\n",
        "        metadata['restrictions'] = [\n",
        "            x.hash if isinstance(x, Restriction) else x\n",
        "            for x in self.restrictions\n",
        "        ]\n",
        "        resource = {\n",
        "            \"name\": f\"projects/{PROJECT_NUMBER}/locations/{LOCATION}/collections/default_collection/dataStores/{DATA_STORE_ID}/branches/0/documents/{self.id}\",\n",
        "            \"id\": self.id,\n",
        "            \"schemaId\": \"default_schema\",\n",
        "            \"structData\": metadata,\n",
        "            \"parentDocumentId\": self.id,\n",
        "            \"content\": {\n",
        "                \"mimeType\": self.mime,\n",
        "                \"uri\": self.uri\n",
        "            }\n",
        "        }\n",
        "        return resource\n",
        "\n",
        "    def create(self):\n",
        "        response = requests.post(\n",
        "            CREATE_DOCUMENT_URL_TEMPLATE.format(self.id),\n",
        "            headers=self._headers(),\n",
        "            json=self.as_resource()\n",
        "        )\n",
        "        print(response)\n",
        "        return response.json()\n",
        "\n",
        "    @classmethod\n",
        "    def from_id(cls, doc_id):\n",
        "        resource = cls.get(doc_id)\n",
        "        metadata = resource['structData']\n",
        "        restrictions = metadata.pop('restrictions', [])\n",
        "        mime = resource['content']['mimeType']\n",
        "        uri = resource['content']['uri']\n",
        "        return cls(doc_id, restrictions, metadata, mime, uri)\n",
        "\n",
        "    @staticmethod\n",
        "    def get(doc_id):\n",
        "        response = requests.get(\n",
        "            DOCUMENT_URL_TEMPLATE.format(doc_id),\n",
        "            headers=Document._headers()\n",
        "        )\n",
        "        if response.status_code != 200:\n",
        "            raise Exception(f'status_code: {response.status_code}')\n",
        "        return response.json()\n",
        "\n",
        "    def wait_till_indexed(self):\n",
        "        sleep_interval = 5\n",
        "        max_waiting_time = sleep_interval * 60\n",
        "        start = time.perf_counter()\n",
        "        while time.perf_counter() - start < max_waiting_time:\n",
        "            print('checking index status...')\n",
        "            response = self.get(self.id)\n",
        "            if 'indexTime' in response:\n",
        "                break\n",
        "            time.sleep(sleep_interval)\n",
        "        return response\n",
        "\n",
        "    def patch(self):\n",
        "        response = requests.patch(\n",
        "            DOCUMENT_URL_TEMPLATE.format(self.id),\n",
        "            headers=self._headers(),\n",
        "            json=self.as_resource()\n",
        "        )\n",
        "        return response.json()\n",
        "\n",
        "    def delete(self):\n",
        "        response = requests.delete(\n",
        "            DOCUMENT_URL_TEMPLATE.format(self.id),\n",
        "            headers=self._headers()\n",
        "        )\n",
        "        return response.json()\n",
        "\n",
        "    def update(self):\n",
        "        # updating could be done with:\n",
        "        # print(self.patch())\n",
        "        # ---\n",
        "        # alternatively with import method (re-importing using in place documents in the API request)\n",
        "        # ---\n",
        "        # at the moment using \"delete and re-create\" workaround\n",
        "        # as patching and importing currently doesn't work correctly due to an internal error:\n",
        "        # \"Path: does not start with gs://\"\n",
        "        print(self.delete())\n",
        "        print(self.create())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6fd46d2-2b0f-4021-8b83-9cc4f763bd7e",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "c6fd46d2-2b0f-4021-8b83-9cc4f763bd7e"
      },
      "source": [
        "# Searching in a data store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5dfeb31e-0ce6-48e3-a913-2766731f3ffe",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "5dfeb31e-0ce6-48e3-a913-2766731f3ffe"
      },
      "outputs": [],
      "source": [
        "def search(query, search_filter):\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json',\n",
        "        'Authorization': f'Bearer {get_token()}'\n",
        "    }\n",
        "    payload = {\n",
        "        \"query\": query,\n",
        "        \"pageSize\": 100,\n",
        "        \"contentSearchSpec\": {\n",
        "            \"searchResultMode\": \"CHUNKS\"\n",
        "        },\n",
        "        \"filter\": search_filter,\n",
        "        \"relevanceThreshold\": \"MEDIUM\",\n",
        "    }\n",
        "    response = requests.post(SEARCH_URL, headers=headers, json=payload)\n",
        "    return response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9140209f-90e1-406b-a1cb-823610f5fc6c",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "9140209f-90e1-406b-a1cb-823610f5fc6c"
      },
      "outputs": [],
      "source": [
        "def search_without_filter(query):\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json',\n",
        "        'Authorization': f'Bearer {get_token()}'\n",
        "    }\n",
        "    payload = {\n",
        "        \"query\": query,\n",
        "        \"pageSize\": 100,\n",
        "        \"contentSearchSpec\": {\n",
        "            \"searchResultMode\": \"CHUNKS\"\n",
        "        },\n",
        "        \"relevanceThreshold\": \"MEDIUM\",\n",
        "    }\n",
        "    response = requests.post(SEARCH_URL, headers=headers, json=payload)\n",
        "    return response.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32aef5c3-44c7-4d35-8f0d-f6f3c4c6c9d6",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "32aef5c3-44c7-4d35-8f0d-f6f3c4c6c9d6"
      },
      "source": [
        "# Building a LangGraph-based multi-agent application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "a269d1a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_tense(tense: Literal['future', 'past', 'n/a']):\n",
        "    \"\"\"used to indicate if the given phrase is about future, past or none of them (n/a)\"\"\"\n",
        "\n",
        "def tools_or_another_agent(state):\n",
        "    print('redirecting to a different agent, calling the tools or finishing...')\n",
        "    return state.get('next_agent') or tools_condition(state)\n",
        "\n",
        "def last_agent(state):\n",
        "    print('redirecting to the last agent...')\n",
        "    return state['agent_history'][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "62cec254-0200-4c95-b2df-ce64449e7828",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "62cec254-0200-4c95-b2df-ce64449e7828"
      },
      "outputs": [],
      "source": [
        "def make_agent(name, llm, tools):\n",
        "    def agent(state):\n",
        "        print(name)\n",
        "        messages = state['messages']\n",
        "\n",
        "        # check if should route to another agent\n",
        "        last_the_same = state['agent_history'] and state['agent_history'][-1] == name\n",
        "        if state.get('next_agent') != name and not last_the_same:\n",
        "            llm_with_tools = llm.bind_tools([detect_tense], tool_choice=True)\n",
        "            system = SystemMessage(\n",
        "                \"\"\"Given this conversation, detect if the next step is to deal with something to do with HVAC docs or Security based docs\n",
        "                if it's not clear then use 'n/a')\"\"\"\n",
        "            )\n",
        "            response = llm_with_tools.invoke(\n",
        "                [system] + [m for m in messages if not isinstance(m, SystemMessage)]\n",
        "            )\n",
        "            tense = response.tool_calls[0]['args']['tense']\n",
        "            if tense != 'n/a':\n",
        "                return {'agent_history': [name], 'next_agent': tense}\n",
        "\n",
        "        # proceed normally\n",
        "        llm_with_tools = llm.bind_tools(tools)\n",
        "        response = llm_with_tools.invoke(messages)\n",
        "        return {'messages': [response], 'agent_history': [name], 'next_agent': None, 'retrieved_documents': []}\n",
        "    return agent\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[List[str], add_messages]\n",
        "    agent_history: Annotated[List[str], operator.add]\n",
        "    next_agent: Optional[str]\n",
        "    retrieved_documents: Annotated[List[list], operator.add]\n",
        "\n",
        "def search_tool(query: str, config: RunnableConfig, state: Annotated[dict, InjectedState]):\n",
        "    \"\"\"this search tool has to be called for any queries on specific companies\"\"\"\n",
        "    current_agent = state['agent_history'][-1]\n",
        "    agent_to_filter = config['configurable']['user_info']['agent_to_filter']\n",
        "    search_filter = agent_to_filter[current_agent]\n",
        "    resp = search(query, search_filter)\n",
        "    titles = set()\n",
        "    chunks = []\n",
        "    try:\n",
        "        for result in resp['results']:\n",
        "            titles.add(result['chunk']['documentMetadata']['title'])\n",
        "            chunks.append(result['chunk']['content'])\n",
        "    except KeyError:\n",
        "        print(resp)\n",
        "    state['retrieved_documents'].append(sorted(titles))  # workaround for debug purposes as LangGraph doesn't support state modifications with tools atm\n",
        "    return list(dict.fromkeys(chunks))  # dedup as the chunks here come from identical docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "abf71956-6296-4791-988a-9aab7fcb6623",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "abf71956-6296-4791-988a-9aab7fcb6623"
      },
      "outputs": [],
      "source": [
        "def runnable_builder(model, *args, **kwargs):\n",
        "    workflow = StateGraph(State)\n",
        "\n",
        "    toolkit = [search_tool]\n",
        "    tool_node = ToolNode(toolkit)\n",
        "\n",
        "    workflow.add_node('coordinator', make_agent('coordinator', model, toolkit))\n",
        "    workflow.add_node('hvacdoc', make_agent('hvacdoc', model, toolkit))\n",
        "    workflow.add_node('secdoc', make_agent('secdoc', model, toolkit))\n",
        "    workflow.add_node('tools', tool_node)\n",
        "\n",
        "    workflow.add_edge(START, 'coordinator')\n",
        "    workflow.add_conditional_edges('coordinator', tools_or_another_agent)\n",
        "    workflow.add_conditional_edges('hvacdoc', tools_or_another_agent)\n",
        "    workflow.add_conditional_edges('secdoc', tools_or_another_agent)\n",
        "    workflow.add_conditional_edges('tools', last_agent)\n",
        "\n",
        "    graph = workflow.compile()\n",
        "    return graph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d01e440e-ed59-40a2-bbae-480825d9adf6",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "d01e440e-ed59-40a2-bbae-480825d9adf6"
      },
      "source": [
        "# Agent Engine deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3d222766-28ac-4327-b371-2e059cd044f1",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "3d222766-28ac-4327-b371-2e059cd044f1"
      },
      "outputs": [],
      "source": [
        "vertexai.init(\n",
        "    project=PROJECT_ID, \n",
        "    location=\"us-central1\",\n",
        "    staging_bucket=f'gs://{BUCKET_NAME}' \n",
        ")\n",
        "\n",
        "re_agent = LangchainAgent(\n",
        "    model='gemini-2.0-flash',\n",
        "    runnable_builder=runnable_builder\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "afdb2489-2c92-462b-9d04-171626c2c1cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "afdb2489-2c92-462b-9d04-171626c2c1cd",
        "outputId": "7fc1187d-66d7-4673-bd48-c188ffb04889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Identified the following requirements: {'cloudpickle': '3.0.0', 'google-cloud-aiplatform': '1.87.0'}\n",
            "The final list of requirements: ['google-cloud-aiplatform[agent_engines,langchain]', 'cloudpickle==3.0.0', 'pydantic==2.11.2', 'requests', 'google-auth', 'langgraph', 'langchain-core']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using bucket data_storage_aiml_hugo\n",
            "Wrote to gs://data_storage_aiml_hugo/agent_engine/agent_engine.pkl\n",
            "Writing to gs://data_storage_aiml_hugo/agent_engine/requirements.txt\n",
            "Creating in-memory tarfile of extra_packages\n",
            "Writing to gs://data_storage_aiml_hugo/agent_engine/dependencies.tar.gz\n",
            "Creating AgentEngine\n",
            "Create AgentEngine backing LRO: projects/1077649599081/locations/us-central1/reasoningEngines/8756836059049885696/operations/2981021317072945152\n",
            "View progress and logs at https://console.cloud.google.com/logs/query?project=big-data-379417\n",
            "AgentEngine created. Resource name: projects/1077649599081/locations/us-central1/reasoningEngines/8756836059049885696\n",
            "To use this AgentEngine in another session:\n",
            "agent_engine = vertexai.agent_engines.get('projects/1077649599081/locations/us-central1/reasoningEngines/8756836059049885696')\n"
          ]
        }
      ],
      "source": [
        "remote_agent = agent_engines.create(\n",
        "    re_agent,\n",
        "    requirements=[\n",
        "        \"google-cloud-aiplatform[agent_engines,langchain]\",\n",
        "        \"cloudpickle==3.0.0\",\n",
        "        \"pydantic==2.11.2\",\n",
        "        \"requests\",\n",
        "        \"google-auth\",\n",
        "        \"langgraph\",\n",
        "        \"langchain-core\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "d4b49981-ea3d-4ed1-ad0c-d35fec00ded8",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "d4b49981-ea3d-4ed1-ad0c-d35fec00ded8"
      },
      "outputs": [],
      "source": [
        "remote_app = agent_engines.AgentEngine('projects/1077649599081/locations/us-central1/reasoningEngines/4354708160783581184')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3543ba1-7895-4e29-9d9d-0ba3cb7efc73",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "e3543ba1-7895-4e29-9d9d-0ba3cb7efc73"
      },
      "source": [
        "# Helper functions for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "13008a72-72f1-4295-a021-432b92e30ef8",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "13008a72-72f1-4295-a021-432b92e30ef8"
      },
      "outputs": [],
      "source": [
        "def show_environment():\n",
        "    print('environment:')\n",
        "    print('\\t', Document.list_all())\n",
        "    print('\\t', Group.all())\n",
        "    print('\\t', User.all())\n",
        "    print('\\t', Agent.all())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1bcb9e04-f4b7-48de-9045-ccefe2a8ddf9",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "1bcb9e04-f4b7-48de-9045-ccefe2a8ddf9"
      },
      "outputs": [],
      "source": [
        "def clear_environment():\n",
        "    for doc_id in [x['id'] for x in Document.list_all().get('documents', [])]:\n",
        "        Document.from_id(doc_id).delete()\n",
        "    Group.clear_all()\n",
        "    User.clear_all()\n",
        "    Agent.clear_all()\n",
        "\n",
        "\n",
        "# def clear_environment():\n",
        "#     all_docs_result = Document.list_all()\n",
        "#     doc_list = all_docs_result. # Use .get() for safety\n",
        "#     if doc_list: # Check if the list is not empty\n",
        "#          for doc_id in [x['id'] for x in doc_list]:\n",
        "#              try: # Add try/except for robustness during deletion\n",
        "#                 doc = Document.from_id(doc_id)\n",
        "#                 if doc: # Ensure from_id didn't return None\n",
        "#                     doc.delete()\n",
        "#              except Exception as e:\n",
        "#                  print(f\"Warning: Failed to delete doc {doc_id}: {e}\")\n",
        "#     Group.clear_all()\n",
        "#     User.clear_all()\n",
        "#     Agent.clear_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "06a24d9e-08dd-4b9d-a90d-a9489601b9ee",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "06a24d9e-08dd-4b9d-a90d-a9489601b9ee"
      },
      "outputs": [],
      "source": [
        "def final_response(state):\n",
        "    return state['messages'][-1]['kwargs']['content']\n",
        "\n",
        "def retrieved_documents(state_or_search_results):\n",
        "    if 'retrieved_documents' in state_or_search_results:\n",
        "        return state_or_search_results['retrieved_documents'][-1]\n",
        "    docs = {x['chunk']['documentMetadata']['title'] for x in state_or_search_results.get('results', [])}\n",
        "    return sorted(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7eae9aa5-ed3d-47b2-a8bf-7d09909d3079",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "7eae9aa5-ed3d-47b2-a8bf-7d09909d3079"
      },
      "outputs": [],
      "source": [
        "def confirm_retrievable(query, doc_title):\n",
        "    sleep_interval = 10\n",
        "    max_waiting_time = sleep_interval * 60\n",
        "    start = time.perf_counter()\n",
        "    successful_attempts = 0\n",
        "    want_successful = 5\n",
        "    while time.perf_counter() - start < max_waiting_time:\n",
        "        print('retrieving... ', end='')\n",
        "        search_results = search_without_filter(query)\n",
        "        retrieved = retrieved_documents(search_results)\n",
        "        if doc_title in retrieved:\n",
        "            print('retrieved')\n",
        "            successful_attempts += 1\n",
        "        else:\n",
        "            print('not retrieved')\n",
        "            successful_attempts = 0\n",
        "        if successful_attempts == want_successful:\n",
        "            break\n",
        "        time.sleep(sleep_interval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "81e04586-bf9b-4435-82ff-dab8149339bb",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "81e04586-bf9b-4435-82ff-dab8149339bb"
      },
      "outputs": [],
      "source": [
        "def confirm_restrictions(query, doc):\n",
        "    sleep_interval = 10\n",
        "    max_waiting_time = sleep_interval * 60\n",
        "    start = time.perf_counter()\n",
        "    successful_attempts = 0\n",
        "    want_successful = 5\n",
        "    while time.perf_counter() - start < max_waiting_time:\n",
        "        print('checking restrictions... ', end='')\n",
        "        search_results = search_without_filter(query)\n",
        "        retrieved_restrictions = (\n",
        "            x['chunk']['documentMetadata']['structData']['restrictions']\n",
        "            for x in search_results.get('results', [])\n",
        "            if x['chunk']['documentMetadata']['title'] == doc.title\n",
        "        )\n",
        "        retrieved_restrictions = sorted(next(retrieved_restrictions, []))\n",
        "        document_restrictions = sorted(\n",
        "            x.hash if isinstance(x, Restriction) else x\n",
        "            for x in doc.restrictions\n",
        "        )\n",
        "        if retrieved_restrictions == document_restrictions:\n",
        "            print('matching')\n",
        "            successful_attempts += 1\n",
        "        else:\n",
        "            print('not matching')\n",
        "            successful_attempts = 0\n",
        "        if successful_attempts == want_successful:\n",
        "            break\n",
        "        time.sleep(sleep_interval)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24d8ad97-fdd1-432b-8760-ab0bce1a2d62",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "24d8ad97-fdd1-432b-8760-ab0bce1a2d62"
      },
      "source": [
        "# Test scenarios"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b38bd3-5e2b-41c3-b701-e8f412c69298",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "91b38bd3-5e2b-41c3-b701-e8f412c69298"
      },
      "source": [
        "## Scenario 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "oMvx572whdcy",
      "metadata": {
        "id": "oMvx572whdcy"
      },
      "outputs": [],
      "source": [
        "Group('CustomerA').restrict_read(Access(scope='HVAC_Documents', specifier='HVAC_Users'))\n",
        "Group('CustomerA').add_member(User('U1'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "0Ayq_D3bdnXO",
      "metadata": {
        "id": "0Ayq_D3bdnXO"
      },
      "outputs": [],
      "source": [
        "for doc_id in [x['id'] for x in Document.list_all()['documents']]:\n",
        "    Document.from_id(doc_id).delete()\n",
        "Group.clear_all()\n",
        "User.clear_all()\n",
        "Agent.clear_all()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9035371",
      "metadata": {},
      "source": [
        "# Access Control System - Scenario 1\n",
        "\n",
        "## Scenario Overview\n",
        "\n",
        "This scenario demonstrates how different users access disjoint sets of documents based on their permissions.\n",
        "\n",
        "## Setup\n",
        "\n",
        "- **User U1** is a member of customer organization HVAC_Users\n",
        "- **User U2** is a member of customer organization C2\n",
        "- **User U1** has read access to resources in the HVAC_Documents scope with specifier HVAC_Users\n",
        "- **User U2** has read access to resources belonging to customer organization C2\n",
        "- **Document D1** belongs to HVAC_Documents with specifier HVAC_Users\n",
        "- **Document D2** belongs to customer organization C2\n",
        "- Both documents are relevant for the same question Q1\n",
        "- **Agent A1** has read access to both organizations' resources\n",
        "\n",
        "## Flow Process\n",
        "\n",
        "### Step 1: Environment Configuration\n",
        "- The system establishes groups, permissions, and document restrictions\n",
        "- Users are assigned to their respective groups\n",
        "- Documents are created with appropriate access restrictions\n",
        "- The agent is given access to both groups\n",
        "\n",
        "### Step 2: Agent Access Verification\n",
        "- A direct search by Agent A1 confirms it can access all documents\n",
        "- This verifies that the agent has proper permissions to both document sets\n",
        "\n",
        "### Step 3: User U1 Query\n",
        "- User U1 asks question Q1\n",
        "- The system calculates the intersection of User U1's permissions and Agent A1's permissions\n",
        "- Agent A1 searches using this combined permission filter\n",
        "- Results show that User U1 can access Document D1 (HVAC_Users document)\n",
        "- Document D2 is filtered out as User U1 lacks access to C2 resources\n",
        "\n",
        "### Step 4: User U2 Query\n",
        "- User U2 asks the same question Q1\n",
        "- The system calculates the intersection of User U2's permissions and Agent A1's permissions\n",
        "- Agent A1 searches using this combined permission filter\n",
        "- Results show that User U2 can access Document D2 (C2 document)\n",
        "- Document D1 is filtered out as User U2 lacks access to HVAC_Users resources\n",
        "\n",
        "## Key Concepts Demonstrated\n",
        "\n",
        "- Users can only access documents from their organization\n",
        "- The same agent can serve multiple users with different access levels\n",
        "- Document visibility is dynamically determined based on user permissions\n",
        "- The system enforces proper information boundaries between organizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96d30fbc-f9b2-449e-a8a5-d9771b903038",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "96d30fbc-f9b2-449e-a8a5-d9771b903038"
      },
      "outputs": [],
      "source": [
        "def scenario_1(re_app):\n",
        "    \"\"\"Users with different permissions accessing disjoint sets of documents\"\"\"\n",
        "    clear_environment()\n",
        "    show_environment()\n",
        "    Group('HVAC_Users').restrict_read(Access(scope='HVAC_Documents', specifier='HVAC_Users'))\n",
        "    Group('HVAC_Users').add_member(User('U1'))\n",
        "    Group('C2').restrict_read(Access(scope='customer', specifier='C2'))\n",
        "    Group('C2').add_member(User('U2'))\n",
        "    documents = [\n",
        "        Document(\n",
        "            id='D1',\n",
        "            restrictions=[Restriction(Access(scope='HVAC_Documents', specifier='HVAC_Users'))],\n",
        "            metadata={},\n",
        "            mime='application/pdf',\n",
        "            uri='gs://data_storage_aiml_hugo/adaptation_of_foundation_models_whitepaper_google_cloud.pdf'\n",
        "        ),\n",
        "        Document(\n",
        "            id='D2',\n",
        "            restrictions=[Restriction(Access(scope='customer', specifier='C2'))],\n",
        "            metadata={},\n",
        "            mime='application/pdf',\n",
        "            uri='gs://data_storage_aiml_hugo/ai_adoption_framework_whitepaper.pdf'\n",
        "        )\n",
        "    ]\n",
        "    for doc in documents:\n",
        "        print(doc.create())\n",
        "        print(doc.wait_till_indexed())\n",
        "    agent_A1 = 'coordinator'\n",
        "    Group('HVAC_Users').add_member(Agent(agent_A1))\n",
        "    Group('C2').add_member(Agent(agent_A1))\n",
        "    question_Q1 = 'what is ACME Corp?'\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
        "        {'role': 'user', 'content': question_Q1}\n",
        "    ]\n",
        "    show_environment()\n",
        "\n",
        "    # == step 2\n",
        "    # Direct search attempt, using the permissions of Agent A1, retrieves all relevant documents for question Q1.\n",
        "    print('\\nstep #2')\n",
        "    search_filter = get_filter(Agent(agent_A1).read_restrictions)\n",
        "    assert search_filter\n",
        "    search_results = search(question_Q1, search_filter)\n",
        "    retrieved = retrieved_documents(search_results)\n",
        "    print(retrieved)\n",
        "    # assert 'document_01' in retrieved\n",
        "    # assert 'document_02' in retrieved\n",
        "\n",
        "    # == step 3\n",
        "    # User U1 asks question Q1.\n",
        "    # Agent A1 uses the search tool.\n",
        "    # Document D1 is present in the search results.\n",
        "    # Document D2 is NOT present in the search results.\n",
        "    print('\\nstep #3')\n",
        "    user_info = {\n",
        "        'agent_to_filter': {\n",
        "            agent_id: get_filter(reconcile_restrictions(User('U1').read_restrictions, agent.read_restrictions))\n",
        "            for agent_id, agent in Agent.all().items()\n",
        "        }\n",
        "    }\n",
        "    state = re_app.query(input={'messages': messages}, config={'configurable': {'user_info': user_info}})\n",
        "    print(final_response(state))\n",
        "    print(state['agent_history'])\n",
        "    retrieved = retrieved_documents(state)\n",
        "    print(retrieved)\n",
        "    assert 'adaptation_of_foundation_models_whitepaper_google_cloud' in retrieved\n",
        "    assert 'ai_adoption_framework_whitepaper' not in retrieved\n",
        "\n",
        "    # == step 4\n",
        "    # User U2 asks question Q1.\n",
        "    # Agent A1 uses the search tool.\n",
        "    # Document D2 is present in the search results.\n",
        "    # Document D1 is NOT present in the search results.\n",
        "    print('\\nstep #4')\n",
        "    user_info = {\n",
        "        'agent_to_filter': {\n",
        "            agent_id: get_filter(reconcile_restrictions(User('U2').read_restrictions, agent.read_restrictions))\n",
        "            for agent_id, agent in Agent.all().items()\n",
        "        }\n",
        "    }\n",
        "    state = re_app.query(input={'messages': messages}, config={'configurable': {'user_info': user_info}})\n",
        "    print(final_response(state))\n",
        "    print(state['agent_history'])\n",
        "    retrieved = retrieved_documents(state)\n",
        "    print(retrieved)\n",
        "    assert 'ai_adoption_framework_whitepaper' in retrieved\n",
        "    assert 'adaptation_of_foundation_models_whitepaper_google_cloud' not in retrieved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "bb4022e3-1a0d-4876-b2e9-cf015ad4eaff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "bb4022e3-1a0d-4876-b2e9-cf015ad4eaff",
        "outputId": "f60b1728-e5d1-4e60-fb4b-43a9d4874dda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "environment:\n",
            "\t {}\n",
            "\t {}\n",
            "\t {}\n",
            "\t {}\n",
            "<Response [200]>\n",
            "{'name': 'projects/1077649599081/locations/global/collections/default_collection/dataStores/test-subfolder_1697051023694/branches/0/documents/D1', 'id': 'D1', 'schemaId': 'default_schema', 'structData': {'restrictions': ['f9b857ba14374d8c5f7fe05067f6d210']}, 'parentDocumentId': 'D1', 'content': {'mimeType': 'application/pdf', 'uri': 'gs://data_storage_aiml_hugo/adaptation_of_foundation_models_whitepaper_google_cloud.pdf'}}\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "{'name': 'projects/1077649599081/locations/global/collections/default_collection/dataStores/test-subfolder_1697051023694/branches/0/documents/D1', 'id': 'D1', 'schemaId': 'default_schema', 'structData': {'restrictions': ['f9b857ba14374d8c5f7fe05067f6d210']}, 'parentDocumentId': 'D1', 'content': {'mimeType': 'application/pdf', 'uri': 'gs://data_storage_aiml_hugo/adaptation_of_foundation_models_whitepaper_google_cloud.pdf'}, 'indexTime': '2025-04-08T00:23:46.864463Z', 'indexStatus': {'pendingMessage': 'Document ingestion and parsing have finished. Document indexing is working in progress.'}}\n",
            "<Response [200]>\n",
            "{'name': 'projects/1077649599081/locations/global/collections/default_collection/dataStores/test-subfolder_1697051023694/branches/0/documents/D2', 'id': 'D2', 'schemaId': 'default_schema', 'structData': {'restrictions': ['257f33442c74c67017fb982b6582c684']}, 'parentDocumentId': 'D2', 'content': {'mimeType': 'application/pdf', 'uri': 'gs://data_storage_aiml_hugo/ai_adoption_framework_whitepaper.pdf'}}\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "checking index status...\n",
            "{'name': 'projects/1077649599081/locations/global/collections/default_collection/dataStores/test-subfolder_1697051023694/branches/0/documents/D2', 'id': 'D2', 'schemaId': 'default_schema', 'structData': {'restrictions': ['257f33442c74c67017fb982b6582c684']}, 'parentDocumentId': 'D2', 'content': {'mimeType': 'application/pdf', 'uri': 'gs://data_storage_aiml_hugo/ai_adoption_framework_whitepaper.pdf'}, 'indexStatus': {'pendingMessage': 'Document ingestion and parsing have finished. Document indexing is working in progress.'}}\n",
            "environment:\n",
            "\t {'documents': [{'name': 'projects/1077649599081/locations/global/collections/default_collection/dataStores/test-subfolder_1697051023694/branches/0/documents/D1', 'id': 'D1', 'schemaId': 'default_schema', 'structData': {'restrictions': ['f9b857ba14374d8c5f7fe05067f6d210']}, 'parentDocumentId': 'D1', 'content': {'mimeType': 'application/pdf', 'uri': 'gs://data_storage_aiml_hugo/adaptation_of_foundation_models_whitepaper_google_cloud.pdf'}, 'indexTime': '2025-04-08T00:24:08.461193330Z', 'indexStatus': {'indexTime': '2025-04-08T00:24:08.461193330Z'}}, {'name': 'projects/1077649599081/locations/global/collections/default_collection/dataStores/test-subfolder_1697051023694/branches/0/documents/D2', 'id': 'D2', 'schemaId': 'default_schema', 'structData': {'restrictions': ['257f33442c74c67017fb982b6582c684']}, 'parentDocumentId': 'D2', 'content': {'mimeType': 'application/pdf', 'uri': 'gs://data_storage_aiml_hugo/ai_adoption_framework_whitepaper.pdf'}, 'indexStatus': {'pendingMessage': 'Document ingestion and parsing have finished. Document indexing is working in progress.'}}]}\n",
            "\t {'HVAC_Users': Group('HVAC_Users'), 'C2': Group('C2')}\n",
            "\t {'U1': User('U1'), 'U2': User('U2')}\n",
            "\t {'coordinator': Agent('coordinator')}\n",
            "\n",
            "step #2\n",
            "[]\n",
            "\n",
            "step #3\n",
            "coordinator\n",
            "redirecting to a different agent, calling the tools or finishing...\n",
            "{'attributionToken': '3AL0WwEKDAjh29G_BhDRjO-MARIkNjdmM2RkOWQtMDAwMC0yNWUxLThjNzItMTQyMjNiYzFkNmRhIgdHRU5FUklDKnyY1rct25iGMYGV9zCb2NMw78HjMKOAlyLxzf0wlZLFMPLZ7TCOvp0VwvCeFdLIiDG1jukwm9a3Lbe3jC2Q97Iw1am3MNS_4jD-lPcw2JiGMc-_4jDsweMwntjTMPTN_TC4jukw9dntMNSynRXYqbcwz8iIMY6RyTDFy_MXMAFKEjB4OTU2ZGFkNTdkZTRhZWYxOFKIAXByb2plY3RzLzEwNzc2NDk1OTkwODEvbG9jYXRpb25zL2dsb2JhbC9jb2xsZWN0aW9ucy9kZWZhdWx0X2NvbGxlY3Rpb24vZW5naW5lcy90ZXN0LWRlbG9pdHRlXzE2OTcwNTA1NTE2OTEvc2VydmluZ0NvbmZpZ3MvZGVmYXVsdF9zZWFyY2g', 'guidedSearchResult': {}, 'summary': {}, 'queryExpansionInfo': {}}\n",
            "redirecting to the last agent...\n",
            "coordinator\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mscenario_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mre_agent\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36mscenario_1\u001b[39m\u001b[34m(re_app)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mstep #3\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     55\u001b[39m user_info = {\n\u001b[32m     56\u001b[39m     \u001b[33m'\u001b[39m\u001b[33magent_to_filter\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m     57\u001b[39m         agent_id: get_filter(reconcile_restrictions(User(\u001b[33m'\u001b[39m\u001b[33mU1\u001b[39m\u001b[33m'\u001b[39m).read_restrictions, agent.read_restrictions))\n\u001b[32m     58\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m agent_id, agent \u001b[38;5;129;01min\u001b[39;00m Agent.all().items()\n\u001b[32m     59\u001b[39m     }\n\u001b[32m     60\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m state = \u001b[43mre_app\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser_info\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_info\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(final_response(state))\n\u001b[32m     63\u001b[39m \u001b[38;5;28mprint\u001b[39m(state[\u001b[33m'\u001b[39m\u001b[33magent_history\u001b[39m\u001b[33m'\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/vertexai/preview/reasoning_engines/templates/langchain.py:612\u001b[39m, in \u001b[36mLangchainAgent.query\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._runnable:\n\u001b[32m    610\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_up()\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m langchain_load_dump.dumpd(\n\u001b[32m--> \u001b[39m\u001b[32m612\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_runnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    613\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2336\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[39m\n\u001b[32m   2334\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2335\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m2336\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2337\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2340\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2341\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2342\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2344\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2345\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2346\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1993\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   1987\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   1988\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   1989\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   1990\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   1991\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   1992\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m1993\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1997\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1998\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1999\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2000\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langgraph/pregel/runner.py:230\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    228\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langgraph/utils/runnable.py:546\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    542\u001b[39m config = patch_config(\n\u001b[32m    543\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    544\u001b[39m )\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m546\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    548\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langgraph/utils/runnable.py:310\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    309\u001b[39m     context.run(_set_config_context, config)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mmake_agent.<locals>.agent\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# proceed normally\u001b[39;00m\n\u001b[32m     22\u001b[39m llm_with_tools = llm.bind_tools(tools)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m response = \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m: [response], \u001b[33m'\u001b[39m\u001b[33magent_history\u001b[39m\u001b[33m'\u001b[39m: [name], \u001b[33m'\u001b[39m\u001b[33mnext_agent\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mretrieved_documents\u001b[39m\u001b[33m'\u001b[39m: []}\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langchain_core/runnables/base.py:5440\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5434\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5435\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5438\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5439\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5441\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5442\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5444\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:331\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     **kwargs: Any,\n\u001b[32m    327\u001b[39m ) -> BaseMessage:\n\u001b[32m    328\u001b[39m     config = ensure_config(config)\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    330\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    341\u001b[39m     ).message\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:894\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    887\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    891\u001b[39m     **kwargs: Any,\n\u001b[32m    892\u001b[39m ) -> LLMResult:\n\u001b[32m    893\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:719\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    718\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    725\u001b[39m         )\n\u001b[32m    726\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    727\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:960\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    959\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    964\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langchain_google_vertexai/chat_models.py:1374\u001b[39m, in \u001b[36mChatVertexAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[39m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_gemini_model:\n\u001b[32m   1373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_non_gemini(messages, stop=stop, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_gemini\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langchain_google_vertexai/chat_models.py:1609\u001b[39m, in \u001b[36mChatVertexAI._generate_gemini\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1602\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_gemini\u001b[39m(\n\u001b[32m   1603\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1604\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1607\u001b[39m     **kwargs: Any,\n\u001b[32m   1608\u001b[39m ) -> ChatResult:\n\u001b[32m-> \u001b[39m\u001b[32m1609\u001b[39m     request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_request_gemini\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1610\u001b[39m     response = _completion_with_retry(\n\u001b[32m   1611\u001b[39m         \u001b[38;5;28mself\u001b[39m.prediction_client.generate_content,\n\u001b[32m   1612\u001b[39m         max_retries=\u001b[38;5;28mself\u001b[39m.max_retries,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1617\u001b[39m         **kwargs,\n\u001b[32m   1618\u001b[39m     )\n\u001b[32m   1619\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gemini_response_to_chat_result(response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langchain_google_vertexai/chat_models.py:1464\u001b[39m, in \u001b[36mChatVertexAI._prepare_request_gemini\u001b[39m\u001b[34m(self, messages, stop, stream, tools, functions, tool_config, safety_settings, cached_content, tool_choice, logprobs, **kwargs)\u001b[39m\n\u001b[32m   1449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prepare_request_gemini\u001b[39m(\n\u001b[32m   1450\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1451\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1462\u001b[39m     **kwargs,\n\u001b[32m   1463\u001b[39m ) -> Union[v1GenerateContentRequest, GenerateContentRequest]:\n\u001b[32m-> \u001b[39m\u001b[32m1464\u001b[39m     system_instruction, contents = \u001b[43m_parse_chat_history_gemini\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_image_bytes_loader_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mperform_literal_eval_on_string_raw_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mperform_literal_eval_on_string_raw_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1469\u001b[39m     formatted_tools = \u001b[38;5;28mself\u001b[39m._tools_gemini(tools=tools, functions=functions)\n\u001b[32m   1470\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tool_config:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code_sample/py/AIML/next_repo/venv_nr/lib/python3.11/site-packages/langchain_google_vertexai/chat_models.py:432\u001b[39m, in \u001b[36m_parse_chat_history_gemini\u001b[39m\u001b[34m(history, imageBytesLoader, convert_system_message_to_human, perform_literal_eval_on_string_raw_content)\u001b[39m\n\u001b[32m    430\u001b[39m         content = {k: \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m merged_content.items()}\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m         content = \u001b[43mparsed_content\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    434\u001b[39m     content = _parse_content(message.content)\n",
            "\u001b[31mIndexError\u001b[39m: list index out of range",
            "During task with name 'coordinator' and id 'c7e6e0a0-1216-ee9c-ea1b-816ccb2f4c5a'"
          ]
        }
      ],
      "source": [
        "scenario_1(re_agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c24693c-6ed7-45f6-9af3-a433ab86ec8b",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "2c24693c-6ed7-45f6-9af3-a433ab86ec8b"
      },
      "source": [
        "## Scenario 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "621cd0e1-3b2c-414a-982f-6f06113a33ff",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "621cd0e1-3b2c-414a-982f-6f06113a33ff"
      },
      "outputs": [],
      "source": [
        "def scenario_2(re_app):\n",
        "    \"\"\"Users accessing documents based on their subscription level\"\"\"\n",
        "\n",
        "    print('scenario #2')\n",
        "    # == step 1\n",
        "    # User U1 is a member of company HVAC_Corp.\n",
        "    # User U1 has read access to resources belonging to HVAC_Corp.\n",
        "    # Document D1 is related to Basic subscription tier.\n",
        "    # Document D2 is related to Premium subscription tier.\n",
        "    # HVAC_Corp has access to resources related to Basic subscription.\n",
        "    # HVAC_Corp has access to resources related to Premium subscription.\n",
        "    # Agent A1 has read access to resources related to Basic subscription.\n",
        "    # Agent A2 has read access to resources related to Premium subscription.\n",
        "    # Document D1 is relevant for question Q1.\n",
        "    # Document D2 is relevant for question Q1.\n",
        "    # Document D1 is relevant for question Q2.\n",
        "    # Document D2 is relevant for question Q2.\n",
        "    print('\\nstep #1')\n",
        "    clear_environment()\n",
        "    show_environment()\n",
        "    Group('HVAC_Corp').restrict_read(Access(scope='company', specifier='HVAC_Corp'))\n",
        "    Group('HVAC_Corp').add_member(User('U1'))\n",
        "    documents = [\n",
        "        Document(\n",
        "            id='D1',\n",
        "            restrictions=[Restriction(Access(scope='subscription', specifier='Basic'))],\n",
        "            metadata={},\n",
        "            mime='application/pdf',\n",
        "            uri='gs://data_storage_aiml_hugo/hvac_basic_resources.pdf'\n",
        "        ),\n",
        "        Document(\n",
        "            id='D2',\n",
        "            restrictions=[Restriction(Access(scope='subscription', specifier='Premium'))],\n",
        "            metadata={},\n",
        "            mime='application/pdf',\n",
        "            uri='gs://data_storage_aiml_hugo/hvac_premium_resources.pdf'\n",
        "        )\n",
        "    ]\n",
        "    for doc in documents:\n",
        "        print(doc.create())\n",
        "        print(doc.wait_till_indexed())\n",
        "    Group('Basic_Tier').restrict_read(Access(scope='subscription', specifier='Basic'))\n",
        "    Group('Premium_Tier').restrict_read(Access(scope='subscription', specifier='Premium'))\n",
        "    Group('Basic_Tier').add_member(Group('HVAC_Corp'))\n",
        "    Group('Premium_Tier').add_member(Group('HVAC_Corp'))\n",
        "    agent_A1 = 'coordinator'\n",
        "    agent_A2 = 'past'\n",
        "    Group('Basic_Tier').add_member(Agent(agent_A1))\n",
        "    Group('Premium_Tier').add_member(Agent(agent_A2))\n",
        "    question_Q1 = 'what are best practices for HVAC installation?'\n",
        "    question_Q2 = 'what were the historical trends in HVAC technology?'\n",
        "    user_info = {\n",
        "        'agent_to_filter': {\n",
        "            agent_id: get_filter(reconcile_restrictions(User('U1').read_restrictions, agent.read_restrictions))\n",
        "            for agent_id, agent in Agent.all().items()\n",
        "        }\n",
        "    }\n",
        "    show_environment()\n",
        "\n",
        "    # == step 2\n",
        "    # Direct search attempt, using the permissions of User U1, retrieves all relevant documents for question Q1.\n",
        "    # Direct search attempt, using the permissions of User U1, retrieves all relevant documents for question Q2.\n",
        "    print('\\nstep #2')\n",
        "    search_filter = get_filter(User('U1').read_restrictions)\n",
        "    assert search_filter\n",
        "    search_results = search(question_Q1, search_filter)\n",
        "    retrieved = retrieved_documents(search_results)\n",
        "    print(retrieved)\n",
        "    assert 'hvac_basic_resources' in retrieved\n",
        "    assert 'hvac_premium_resources' in retrieved\n",
        "    search_results = search(question_Q2, search_filter)\n",
        "    retrieved = retrieved_documents(search_results)\n",
        "    print(retrieved)\n",
        "    assert 'hvac_basic_resources' in retrieved\n",
        "    assert 'hvac_premium_resources' in retrieved\n",
        "\n",
        "    # == step 3\n",
        "    # User U1 asks question Q1.\n",
        "    # Agent A1 uses the search tool.\n",
        "    # Document D1 is present in the search results.\n",
        "    # Document D2 is NOT present in the search results.\n",
        "    print('\\nstep #3')\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': 'You are a helpful assistant for HVAC professionals.'},\n",
        "        {'role': 'user', 'content': question_Q1}\n",
        "    ]\n",
        "    state = re_app.query(input={'messages': messages}, config={'configurable': {'user_info': user_info}})\n",
        "    print(final_response(state))\n",
        "    print(state['agent_history'])\n",
        "    retrieved = retrieved_documents(state)\n",
        "    print(retrieved)\n",
        "    assert 'hvac_basic_resources' in retrieved\n",
        "    assert 'hvac_premium_resources' not in retrieved\n",
        "\n",
        "    # == step 4\n",
        "    # User U1 asks question Q2.\n",
        "    # Agent A2 uses the search tool.\n",
        "    # Document D1 is NOT present in the search results.\n",
        "    # Document D2 is present in the search results.\n",
        "    print('\\nstep #4')\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': 'You are a helpful assistant for HVAC professionals.'},\n",
        "        {'role': 'user', 'content': question_Q2}\n",
        "    ]\n",
        "    state = re_app.query(input={'messages': messages}, config={'configurable': {'user_info': user_info}})\n",
        "    print(final_response(state))\n",
        "    print(state['agent_history'])\n",
        "    retrieved = retrieved_documents(state)\n",
        "    print(retrieved)\n",
        "    assert 'hvac_basic_resources' not in retrieved\n",
        "    assert 'hvac_premium_resources' in retrieved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a60ad1f6-ea15-4c5f-b106-36cb84b8d124",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "a60ad1f6-ea15-4c5f-b106-36cb84b8d124",
        "outputId": "f39b383c-2364-4b25-832a-0f08ac52a0fc"
      },
      "outputs": [],
      "source": [
        "scenario_2(remote_app)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55ccc3bf-9690-47b6-9bdb-d5bbabc86eed",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "55ccc3bf-9690-47b6-9bdb-d5bbabc86eed"
      },
      "source": [
        "## Scenario 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e76e13a-da85-4593-a427-1ce32a798979",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "7e76e13a-da85-4593-a427-1ce32a798979"
      },
      "outputs": [],
      "source": [
        "def scenario_3(re_app):\n",
        "    \"\"\"Changing permissions for a user reflected in search results\"\"\"\n",
        "\n",
        "    print('scenario #3')\n",
        "    # == step 1\n",
        "    # User U1 is a member of company HVAC_Corp.\n",
        "    # User U1 has read access to resources belonging to HVAC_Corp.\n",
        "    # Document D1 belongs to HVAC_Corp's company documents.\n",
        "    # Document D2 is related to Premium feature documentation.\n",
        "    # Premium subscription tier has read access to Premium feature documentation.\n",
        "    # Document D1 is relevant for question Q1.\n",
        "    # Document D2 is relevant for question Q1.\n",
        "    # Agent A1 has read access to resources belonging to HVAC_Corp.\n",
        "    # Agent A1 has read access to resources related to Premium features.\n",
        "    print('\\nstep #1')\n",
        "    # clear_environment()\n",
        "    show_environment()\n",
        "    Group('HVAC_Corp').restrict_read(Access(scope='company', specifier='HVAC_Corp'))\n",
        "    Group('HVAC_Corp').add_member(User('U1'))\n",
        "    documents = [\n",
        "        Document(\n",
        "            id='D1',\n",
        "            restrictions=[Restriction(Access(scope='company', specifier='HVAC_Corp'))],\n",
        "            metadata={},\n",
        "            mime='application/pdf',\n",
        "            uri='gs://data_storage_aiml_hugo/hvac_company_manual.pdf'\n",
        "        ),\n",
        "        Document(\n",
        "            id='D2',\n",
        "            restrictions=[Restriction(Access(scope='subscription', specifier='Premium'))],\n",
        "            metadata={},\n",
        "            mime='application/pdf',\n",
        "            uri='gs://data_storage_aiml_hugo/hvac_premium_features.pdf'\n",
        "        )\n",
        "    ]\n",
        "    for doc in documents:\n",
        "        print(doc.create())\n",
        "        print(doc.wait_till_indexed())\n",
        "    Group('Premium_Tier').restrict_read(Access(scope='subscription', specifier='Premium'))\n",
        "    Group('Premium_Tier').add_member(Group('Premium_Subscribers'))\n",
        "    agent_A1 = 'future'\n",
        "    Group('HVAC_Corp').add_member(Agent(agent_A1))\n",
        "    Group('Premium_Tier').add_member(Agent(agent_A1))\n",
        "    question_Q1 = 'what are the upcoming HVAC technologies?'\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': 'You are a helpful assistant for HVAC professionals.'},\n",
        "        {'role': 'user', 'content': question_Q1}\n",
        "    ]\n",
        "    show_environment()\n",
        "\n",
        "    # == step 2\n",
        "    # Direct search attempt, using the permissions of Agent A1, retrieves all relevant documents for question Q1.\n",
        "    print('\\nstep #2')\n",
        "    search_filter = get_filter(Agent(agent_A1).read_restrictions)\n",
        "    assert search_filter\n",
        "    search_results = search(question_Q1, search_filter)\n",
        "    retrieved = retrieved_documents(search_results)\n",
        "    print(retrieved)\n",
        "    assert 'hvac_company_manual' in retrieved\n",
        "    assert 'hvac_premium_features' in retrieved\n",
        "\n",
        "    # == step 3\n",
        "    # User U1 asks question Q1.\n",
        "    # Agent A1 uses the search tool.\n",
        "    # Document D1 is present in the search results.\n",
        "    # Document D2 is NOT present in the search results.\n",
        "    print('\\nstep #3')\n",
        "    user_info = {\n",
        "        'agent_to_filter': {\n",
        "            agent_id: get_filter(reconcile_restrictions(User('U1').read_restrictions, agent.read_restrictions))\n",
        "            for agent_id, agent in Agent.all().items()\n",
        "        }\n",
        "    }\n",
        "    state = re_app.query(input={'messages': messages}, config={'configurable': {'user_info': user_info}})\n",
        "    print(final_response(state))\n",
        "    print(state['agent_history'])\n",
        "    retrieved = retrieved_documents(state)\n",
        "    print(retrieved)\n",
        "    assert 'hvac_company_manual' in retrieved\n",
        "    assert 'hvac_premium_features' not in retrieved\n",
        "\n",
        "    # == step 4\n",
        "    # HVAC_Corp upgrades to Premium subscription tier.\n",
        "    # User U1 asks question Q1.\n",
        "    # Agent A1 uses the search tool.\n",
        "    # Document D1 is present in the search results.\n",
        "    # Document D2 is present in the search results.\n",
        "    print('\\nstep #4')\n",
        "    Group('Premium_Subscribers').add_member(Group('HVAC_Corp'))\n",
        "    user_info = {\n",
        "        'agent_to_filter': {\n",
        "            agent_id: get_filter(reconcile_restrictions(User('U1').read_restrictions, agent.read_restrictions))\n",
        "            for agent_id, agent in Agent.all().items()\n",
        "        }\n",
        "    }\n",
        "    state = re_app.query(input={'messages': messages}, config={'configurable': {'user_info': user_info}})\n",
        "    print(final_response(state))\n",
        "    print(state['agent_history'])\n",
        "    retrieved = retrieved_documents(state)\n",
        "    print(retrieved)\n",
        "    assert 'hvac_company_manual' in retrieved\n",
        "    assert 'hvac_premium_features' in retrieved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0d9b260-0de5-486d-bcb4-28651a0b1536",
      "metadata": {
        "deletable": true,
        "editable": true,
        "frozen": false,
        "id": "a0d9b260-0de5-486d-bcb4-28651a0b1536",
        "outputId": "8559edf5-3849-4a3a-d353-5de6c1824ea5"
      },
      "outputs": [],
      "source": [
        "scenario_3(remote_app)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0181adb7-0422-4a27-9fd4-7f2a6df39e77",
      "metadata": {
        "id": "0181adb7-0422-4a27-9fd4-7f2a6df39e77"
      },
      "source": [
        "## DB design matching the class design"
      ]
    },
    {
      "cell_type": "raw",
      "id": "6a88ba4e-c37a-47c4-97fe-5eb36eec5c2c",
      "metadata": {
        "id": "6a88ba4e-c37a-47c4-97fe-5eb36eec5c2c"
      },
      "source": [
        "Access:\n",
        "- id\n",
        "- scope\n",
        "- specifier\n",
        "\n",
        "Restriction:\n",
        "- id\n",
        "\n",
        "RestrictionHasAccess:\n",
        "- restriction_id\n",
        "- access_id\n",
        "\n",
        "Principal:\n",
        "- id\n",
        "- read_restriction (restriction_id)\n",
        "- write_restriction (restriction_id)\n",
        "- is_group (true | false)\n",
        "\n",
        "PrincipalIsMemberOfGroup\n",
        "- principal_id\n",
        "- group_id (principal_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cfc4229-5e17-4b49-afca-7eef59011687",
      "metadata": {
        "id": "8cfc4229-5e17-4b49-afca-7eef59011687"
      },
      "source": [
        "## Alternative DB design (without groups)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "4f3a750f-a629-411b-a02f-5f2599c0afda",
      "metadata": {
        "id": "4f3a750f-a629-411b-a02f-5f2599c0afda"
      },
      "source": [
        "Access:\n",
        "- id\n",
        "- scope\n",
        "- specifier\n",
        "\n",
        "Restriction:\n",
        "- id\n",
        "\n",
        "RestrictionHasAccess:\n",
        "- restriction_id\n",
        "- access_id\n",
        "\n",
        "Principal:\n",
        "- id\n",
        "\n",
        "PrincipalHasRestriction:\n",
        "- principal_id\n",
        "- restriction_id\n",
        "- restriction_type (read | write)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5df3a04c-2f95-4daf-ac84-8189a9642760",
      "metadata": {
        "id": "5df3a04c-2f95-4daf-ac84-8189a9642760"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_nr",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
